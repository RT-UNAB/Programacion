{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN SkinTears v4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RT-UNAB/Programacion/blob/main/CNN_SkinTears_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiIW8xwB1PnP",
        "outputId": "2498708a-fbfb-4619-9cf0-252bf8079aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# VERIFICO SI ESTA ACTIVA LA GPU\n",
        "\n",
        "import tensorflow as tf\n",
        "print (\"La GPU esta activa???     \", tf.test.is_gpu_available(),\"\\n\\n\")\n",
        "\n",
        "\n",
        "# CONSTRUYENDO LA CNN (Convolutional Neural Network)\n",
        "# IMPORTO LAS LIBRERIAS\n",
        "\n",
        "# https://medium.com/nybles/create-your-first-image-recognition-classifier-using-cnn-keras-and-tensorflow-backend-6eaab98d14dd\n",
        "\n",
        "# IMPORTO LIBRERIAS Y PAQUETES DE KERAS\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# MONTO MI GOOGLE DRIVE, PARA POSTERIORMENTE LEER LAS IMAGENES\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La GPU esta activa???      True \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IHdmsZiPcFb",
        "outputId": "f5a42785-788d-47aa-ef1a-79b0da62b741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# PREPROCESO LAS IMAGENES GENERANDO MAS DATA\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   vertical_flip = True,\n",
        "                                   validation_split=0.1)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    directory='/content/gdrive/My Drive/SkinTears/dataset/training_set', \n",
        "    target_size = (128, 128), \n",
        "    batch_size = 32, \n",
        "    class_mode = 'categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    directory='/content/gdrive/My Drive/SkinTears/dataset/test_set', \n",
        "    target_size = (128, 128), \n",
        "    batch_size = 32, \n",
        "    class_mode = 'categorical')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16444 images belonging to 4 classes.\n",
            "Found 4166 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncYTASjN4PAO",
        "outputId": "e0913cba-2731-48bf-d4f0-63f71638aa76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# PASO 1 - CONVOLUTION\n",
        "# extrae características de la imagen de entrada. preserva la relación espacial entre los píxeles al aprender las características de la imagen utilizando pequeños cuadrados de datos de entrada.\n",
        "classifier.add(Convolution2D(32, 3, 3, input_shape = (128, 128, 3), activation = 'relu'))\n",
        "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
        "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
        "\n",
        "# PASO 2 - POOLING\n",
        "# también llamada submuestreo o submuestreo, reduce la dimensionalidad de cada mapa de características, pero conserva la información más importante.\n",
        "# En el caso de Max Pooling, definimos una vecindad espacial (por ejemplo, una ventana de 2 × 2) y tomamos el elemento más grande del mapa de características rectificado dentro de esa ventana\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# SE AGREGA UNA SEGUNDA CAPA CONVOLUTIONAL\n",
        "classifier.add(Convolution2D(64, 3, 3, activation = 'relu'))\n",
        "classifier.add(Convolution2D(64, 3, 3, activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# SE AGREGA UNA TERCERA CAPA CONVOLUTIONAL\n",
        "classifier.add(Convolution2D(128, 3, 3, activation = 'relu'))\n",
        "classifier.add(Convolution2D(128, 3, 3, activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#*************************************************************\n",
        "\n",
        "# SE AGREGA UNA CUARTA CAPA CONVOLUTIONAL\n",
        "classifier.add(Convolution2D(256, 3, 3, activation = 'relu'))\n",
        "classifier.add(Convolution2D(256, 3, 3, activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "\n",
        "#*************************************************************\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# PASO 3 - FLATTENING\n",
        "# Aquí la matriz se convierte en una matriz lineal de modo que se ingrese en los nodos de nuestra red neuronal.\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# PASO 4 - FULL CONNECTION\n",
        "# conectamos nuestra red convolucional a una red neuronal para luego compilar nuestra red.\n",
        "\n",
        "\n",
        "\n",
        "# hemos creado una red neuronal de 2 capas con una función softmax como función de activación para la última capa.\n",
        "# ya que necesitamos encontrar la probabilidad de que la imagens sea T0, T1, T2 o T3.\n",
        "classifier.add(Dropout(0.3))\n",
        "classifier.add(Dense(output_dim = 1024, activation = 'relu'))\n",
        "classifier.add(Dropout(0.3))\n",
        "classifier.add(Dense(output_dim = 4, activation=\"softmax\"))\n",
        "\n",
        "\n",
        "\n",
        "# COMPILO LA CNN\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "classifier.fit_generator(\n",
        "    training_set, \n",
        "    nb_epoch = 30)\n",
        "\n",
        "\n",
        "\n",
        "# GUARDO EL CLASIFICADOR EN UN ARCHIVO H5\n",
        "# para analizar imagenes rapidamente invocando este modelo.\n",
        "classifier.save('/content/gdrive/My Drive/SkinTears/modelo_SkinTears_v4.h5')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0904 16:56:51.531615 139883980339072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(128, 128,..., activation=\"relu\")`\n",
            "  \"\"\"\n",
            "W0904 16:56:51.546093 139883980339072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0904 16:56:51.556627 139883980339072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  import sys\n",
            "W0904 16:56:51.618115 139883980339072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "W0904 16:56:51.722983 139883980339072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0904 16:56:51.735411 139883980339072 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=1024)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=4)`\n",
            "W0904 16:56:51.806671 139883980339072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0904 16:56:51.832180 139883980339072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., epochs=30)`\n",
            "W0904 16:56:52.051513 139883980339072 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "514/514 [==============================] - 9822s 19s/step - loss: 0.9713 - acc: 0.5455\n",
            "Epoch 2/30\n",
            "514/514 [==============================] - 511s 994ms/step - loss: 0.6251 - acc: 0.7439\n",
            "Epoch 3/30\n",
            "514/514 [==============================] - 498s 969ms/step - loss: 0.5520 - acc: 0.7758\n",
            "Epoch 4/30\n",
            "514/514 [==============================] - 499s 971ms/step - loss: 0.4075 - acc: 0.8408\n",
            "Epoch 5/30\n",
            "514/514 [==============================] - 491s 954ms/step - loss: 0.3315 - acc: 0.8734\n",
            "Epoch 6/30\n",
            "514/514 [==============================] - 493s 960ms/step - loss: 0.2677 - acc: 0.9002\n",
            "Epoch 7/30\n",
            "514/514 [==============================] - 492s 957ms/step - loss: 0.2222 - acc: 0.9186\n",
            "Epoch 8/30\n",
            "514/514 [==============================] - 506s 984ms/step - loss: 0.2330 - acc: 0.9131\n",
            "Epoch 9/30\n",
            "514/514 [==============================] - 505s 983ms/step - loss: 0.1948 - acc: 0.9279\n",
            "Epoch 10/30\n",
            "514/514 [==============================] - 511s 995ms/step - loss: 0.1788 - acc: 0.9382\n",
            "Epoch 11/30\n",
            "514/514 [==============================] - 499s 971ms/step - loss: 0.1504 - acc: 0.9461\n",
            "Epoch 12/30\n",
            "514/514 [==============================] - 511s 994ms/step - loss: 0.1448 - acc: 0.9477\n",
            "Epoch 13/30\n",
            "514/514 [==============================] - 506s 984ms/step - loss: 0.1486 - acc: 0.9475\n",
            "Epoch 14/30\n",
            "514/514 [==============================] - 510s 993ms/step - loss: 0.1245 - acc: 0.9568\n",
            "Epoch 15/30\n",
            "514/514 [==============================] - 514s 999ms/step - loss: 0.1421 - acc: 0.9533\n",
            "Epoch 16/30\n",
            "514/514 [==============================] - 511s 995ms/step - loss: 0.1049 - acc: 0.9638\n",
            "Epoch 17/30\n",
            "514/514 [==============================] - 512s 997ms/step - loss: 0.1153 - acc: 0.9605\n",
            "Epoch 18/30\n",
            "514/514 [==============================] - 515s 1s/step - loss: 0.1105 - acc: 0.9614\n",
            "Epoch 19/30\n",
            "514/514 [==============================] - 511s 994ms/step - loss: 0.0970 - acc: 0.9665\n",
            "Epoch 20/30\n",
            "514/514 [==============================] - 509s 990ms/step - loss: 0.0986 - acc: 0.9661\n",
            "Epoch 21/30\n",
            "514/514 [==============================] - 511s 994ms/step - loss: 0.1062 - acc: 0.9641\n",
            "Epoch 22/30\n",
            "514/514 [==============================] - 516s 1s/step - loss: 0.0811 - acc: 0.9727\n",
            "Epoch 23/30\n",
            "514/514 [==============================] - 515s 1s/step - loss: 0.0864 - acc: 0.9709\n",
            "Epoch 24/30\n",
            "514/514 [==============================] - 512s 996ms/step - loss: 0.0875 - acc: 0.9701\n",
            "Epoch 25/30\n",
            "514/514 [==============================] - 510s 992ms/step - loss: 0.0813 - acc: 0.9710\n",
            "Epoch 26/30\n",
            "514/514 [==============================] - 510s 992ms/step - loss: 0.0958 - acc: 0.9700\n",
            "Epoch 27/30\n",
            "514/514 [==============================] - 506s 984ms/step - loss: 0.0808 - acc: 0.9735\n",
            "Epoch 28/30\n",
            "514/514 [==============================] - 503s 978ms/step - loss: 0.0721 - acc: 0.9749\n",
            "Epoch 29/30\n",
            "514/514 [==============================] - 502s 976ms/step - loss: 0.0637 - acc: 0.9800\n",
            "Epoch 30/30\n",
            "514/514 [==============================] - 499s 971ms/step - loss: 0.0663 - acc: 0.9776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYIKjV174U3K",
        "outputId": "76cf299e-3dae-4e47-aab4-f8e02ddf9308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Fitting the CNN to the images\n",
        "\n",
        "from tensorflow import keras\n",
        "classifier = keras.models.load_model('/content/gdrive/My Drive/SkinTears/modelo_SkinTears_v4.h5')\n",
        "\n",
        "# Evaluacion del conjunto de imagenes de test\n",
        "classifier.evaluate_generator(test_set, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "131/131 [==============================] - 2377s 18s/step - loss: 0.8735 - acc: 0.7345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8734798305134737, 0.7345175]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp56CIY6dASj",
        "outputId": "41669c4f-0763-4bdc-d9c5-dcae4d2664e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# VERIFICO QUE PUEDO GUARDAR Y LEER UN ARCHIVO ALMACENADO EN MI GOOGLE DRIVE COMO VERIFICACION DE CONECCION\n",
        "\n",
        "with open('/content/gdrive/My Drive/CNNExamples/Ej4/dataset/LINKS.txt', 'w') as f:\n",
        "  f.write('Hola Google Drive!')\n",
        "!cat /content/gdrive/My\\ Drive/CNNExamples/Ej4/dataset/LINKS.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello Google Drive!"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLVT9RmTFL3j"
      },
      "source": [
        "\"\"\"\n",
        "# HAGO PREDICCIONES CON EL MODELO GUARDADO EXTENSION H5 POR EL CLASIFICADOR SOBRE UNA IMAGEN PUNTUAL\n",
        "from tensorflow import keras\n",
        "\n",
        "classifier = keras.models.load_model('/content/gdrive/My Drive/Colab Notebooks/clasificador_entrenado_SkinTears10000_4Class.h5')\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/gdrive/My Drive/CNNExamples/SkinTears/dataset/test_set/T2/T2.40.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = classifier.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] >= 0.5:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'\n",
        "print(prediction)\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW0g0-BjwO7m",
        "outputId": "cc185dd9-d35a-42d4-8251-5298613fc1ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# HAGO PREDICCIONES CON EL MODELO GUARDADO DE EXTENSION H5, SOBRE UNA IMAGEN PUNTUAL\n",
        "from tensorflow import keras\n",
        "\n",
        "classifier = keras.models.load_model('/content/gdrive/My Drive/SkinTears/modelo_SkinTears.h5')\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/gdrive/My Drive/SkinTears/dataset/test_set/Tipo0/SkinTear_T0_20.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = classifier.predict(test_image)\n",
        "\n",
        "#training_set.class_indices\n",
        "\n",
        "clase = np.argmax(result, axis=-1)\n",
        "conf = np.max(result, axis=-1)\n",
        "print (result, conf)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. 0.]] [1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5aeTCFMG17x"
      },
      "source": [
        "# CONVIERTO MODELO H5 A TFLITE METODO 1 ----------- FUNCIONA OK ! ! !\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import lite\n",
        "\n",
        "converter = lite.TFLiteConverter.from_keras_model_file(\"/content/gdrive/My Drive/Colab Notebooks/clasificador_entrenado_SkinTears10000_4ClassDM.h5\")\n",
        "tflite_model = converter.convert()\n",
        "open(\"/content/gdrive/My Drive/Colab Notebooks/converted_model.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tos9uUHapzcQ",
        "outputId": "279cc556-6bd8-4664-827a-bb417b2b141a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "# CONVIERTO MODELO H5 A PB METODO 1 ----------- FUNCIONA OK ! ! !\n",
        "# This was created with @warptime's help. Thank you!\n",
        "\n",
        "from tensorflow.python.framework import graph_util\n",
        "from tensorflow.python.framework import graph_io\n",
        "from keras.models import load_model\n",
        "from keras import backend as K\n",
        "import os.path as osp\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "model = load_model('/content/gdrive/My Drive/SkinTears/modelo_SkinTears.h5')\n",
        "nb_classes = 4 # The number of output nodes in the model\n",
        "prefix_output_node_names_of_final_network = 'output_node_NEW'\n",
        "\n",
        "K.set_learning_phase(0)\n",
        "\n",
        "pred = [None]*nb_classes\n",
        "pred_node_names = [None]*nb_classes\n",
        "for i in range(nb_classes):\n",
        "    pred_node_names[i] = prefix_output_node_names_of_final_network+str(i)\n",
        "    pred[i] = tf.identity(model.output[i], name=pred_node_names[i])\n",
        "print('output nodes names are: ', pred_node_names)\n",
        "\n",
        "sess = K.get_session()\n",
        "output_fld = 'tensorflow_model/'\n",
        "if not os.path.isdir(output_fld):\n",
        "    os.mkdir(output_fld)\n",
        "output_graph_name = '/content/gdrive/My Drive/SkinTears/saved_model_path' + '.pb'\n",
        "output_graph_suffix = '_inference'\n",
        "\n",
        "constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)\n",
        "graph_io.write_graph(constant_graph, output_fld, output_graph_name, as_text=False)\n",
        "print('saved the constant graph (ready for inference) at: ', osp.join(output_fld, output_graph_name))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0816 18:31:51.936748 140637674309504 deprecation.py:323] From <ipython-input-4-d0a9d8bc6f95>:31: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0816 18:31:51.937840 140637674309504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "output nodes names are:  ['output_node_NEW0', 'output_node_NEW1', 'output_node_NEW2', 'output_node_NEW3']\n",
            "saved the constant graph (ready for inference) at:  /content/gdrive/My Drive/Colab Notebooks/NEW_TEST_saved_model_path.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h7sApZgBEAH"
      },
      "source": [
        "# PROBAR QUE HACE ESTE CODIGO\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "path = \"ruta/al/modelo.pb\"\n",
        "#Cargamos el archivo pb como graphdef\n",
        "with tf.io.gfile.GFile(path, \"rb\") as fid:\n",
        "  graph_def = tf.GraphDef()\n",
        "  graph_def.ParseFromString(fid.read())\n",
        "\n",
        "graph = tf.get_default_graph()\n",
        "tf.import_graph_def(graph_def, name=\"heridas\")\n",
        "\n",
        "entrada = graph.get_tensor_by_name(\"heridas/conv2d_1_input:0\")\n",
        "salida = graph.get_tensor_by_name(\"heridas/nombre_out:0\")\n",
        "\n",
        "with tf.Session(graph=graph) as sess:\n",
        "  resultado = sess.run(salida, feed_dict={entrada:imagen})\n",
        "  print(resultado) #[1,0,0,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "628LvU8BBtKi",
        "outputId": "ae129093-19d9-4597-f1f3-db4fd62b594b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8xAM-blkZfu",
        "outputId": "a58fc4be-c894-4616-defe-110dc98e1c60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# INDICAR LA RUTA DEL ARCHIVO PB\n",
        "\n",
        "filename = \"/content/gdrive/My Drive/SkinTears/modelo_SkinTears.pb\"\n",
        "import tensorflow as tf\n",
        "g = tf.GraphDef()\n",
        "g.ParseFromString(open(filename, 'rb').read())\n",
        "print()\n",
        "print(filename)\n",
        "print(\"=======================INPUT=========================\")\n",
        "print([n for n in g.node if n.name.find('input') != -1])\n",
        "print(\"=======================OUTPUT========================\")\n",
        "print([n for n in g.node if n.name.find('output') != -1])\n",
        "print(\"===================KERAS_LEARNING=====================\")\n",
        "print([n for n in g.node if n.name.find('keras_learning_phase') != -1])\n",
        "print(\"======================================================\")\n",
        "print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/content/gdrive/My Drive/Colab Notebooks/TEST_saved_model_path.pb\n",
            "=======================INPUT=========================\n",
            "[name: \"conv2d_1_input\"\n",
            "op: \"Placeholder\"\n",
            "attr {\n",
            "  key: \"dtype\"\n",
            "  value {\n",
            "    type: DT_FLOAT\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"shape\"\n",
            "  value {\n",
            "    shape {\n",
            "      dim {\n",
            "        size: -1\n",
            "      }\n",
            "      dim {\n",
            "        size: 128\n",
            "      }\n",
            "      dim {\n",
            "        size: 128\n",
            "      }\n",
            "      dim {\n",
            "        size: 3\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", name: \"dropout_1/keras_learning_phase/input\"\n",
            "op: \"Const\"\n",
            "attr {\n",
            "  key: \"dtype\"\n",
            "  value {\n",
            "    type: DT_BOOL\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"value\"\n",
            "  value {\n",
            "    tensor {\n",
            "      dtype: DT_BOOL\n",
            "      tensor_shape {\n",
            "      }\n",
            "      bool_val: false\n",
            "    }\n",
            "  }\n",
            "}\n",
            "]\n",
            "=======================OUTPUT========================\n",
            "[name: \"output_node_NEW0\"\n",
            "op: \"Identity\"\n",
            "input: \"strided_slice\"\n",
            "attr {\n",
            "  key: \"T\"\n",
            "  value {\n",
            "    type: DT_FLOAT\n",
            "  }\n",
            "}\n",
            ", name: \"output_node_NEW1\"\n",
            "op: \"Identity\"\n",
            "input: \"strided_slice_1\"\n",
            "attr {\n",
            "  key: \"T\"\n",
            "  value {\n",
            "    type: DT_FLOAT\n",
            "  }\n",
            "}\n",
            ", name: \"output_node_NEW2\"\n",
            "op: \"Identity\"\n",
            "input: \"strided_slice_2\"\n",
            "attr {\n",
            "  key: \"T\"\n",
            "  value {\n",
            "    type: DT_FLOAT\n",
            "  }\n",
            "}\n",
            ", name: \"output_node_NEW3\"\n",
            "op: \"Identity\"\n",
            "input: \"strided_slice_3\"\n",
            "attr {\n",
            "  key: \"T\"\n",
            "  value {\n",
            "    type: DT_FLOAT\n",
            "  }\n",
            "}\n",
            "]\n",
            "===================KERAS_LEARNING=====================\n",
            "[name: \"dropout_1/keras_learning_phase/input\"\n",
            "op: \"Const\"\n",
            "attr {\n",
            "  key: \"dtype\"\n",
            "  value {\n",
            "    type: DT_BOOL\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"value\"\n",
            "  value {\n",
            "    tensor {\n",
            "      dtype: DT_BOOL\n",
            "      tensor_shape {\n",
            "      }\n",
            "      bool_val: false\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", name: \"dropout_1/keras_learning_phase\"\n",
            "op: \"PlaceholderWithDefault\"\n",
            "input: \"dropout_1/keras_learning_phase/input\"\n",
            "attr {\n",
            "  key: \"dtype\"\n",
            "  value {\n",
            "    type: DT_BOOL\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"shape\"\n",
            "  value {\n",
            "    shape {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "]\n",
            "======================================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdpJvPQMINZS",
        "outputId": "f7732bf4-3a62-4e48-d318-fb09a4b1748d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "saved_model_path=\"/content/gdrive/My Drive/SkinTears/TEST_saved_model_path.pb\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "new_model = tf.contrib.saved_model.load_keras_model(saved_model_path)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "new_model = tf.keras.experimental.load_from_saved_model(saved_model_path)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-85eae570cf3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model.py\u001b[0m in \u001b[0;36mload_from_saved_model\u001b[0;34m(saved_model_path, custom_objects)\u001b[0m\n\u001b[1;32m    397\u001b[0m       \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mASSETS_DIRECTORY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m       compat.as_bytes(constants.SAVED_MODEL_FILENAME_JSON))\n\u001b[0;32m--> 399\u001b[0;31m   \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mread_file_to_string\u001b[0;34m(filename, binary_mode)\u001b[0m\n\u001b[1;32m    331\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    120\u001b[0m       \u001b[0mstring\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mregular\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \"\"\"\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m       \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m                                            \"File isn't open for reading\")\n\u001b[1;32m     83\u001b[0m       self._read_buf = pywrap_tensorflow.CreateBufferedInputStream(\n\u001b[0;32m---> 84\u001b[0;31m           compat.as_bytes(self.__name), 1024 * 512)\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prewrite_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: /content/gdrive/My Drive/Colab Notebooks/TEST_saved_model_path.pb/assets/saved_model.json; Not a directory"
          ]
        }
      ]
    }
  ]
}